{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0fd2a7",
   "metadata": {},
   "source": [
    "## Using Python to Integrate MongoDB Data into an ETL Process\n",
    "Modern Data Warehousing and Analytics solutions frequently use languages like Python or Scala to extract data from numerous sources, including relational database management systems, NoSQL database systems, real-time streaming endpoints and Data Lakes. These languages can then be used to perform many types of transformation before then loading the data into a variety of destinations including file systems and data warehouses. This data can then be consumed by data scientists or business analysts.\n",
    "\n",
    "In this lab you will build upon the **Northwind_DW2** dimensional database from Lab 3; however, you will be integrating new data sourced from an instance of MongoDB. The new data will be concerned with new business processes; inventory and purchasing. You will continue to interact with both the source systems (MongoDB and MySQL), and the destination system (the Northwind_DW2 data warehouse) from a remote client running Python (Jupyter Notebooks). \n",
    "\n",
    "Just as in Lab 3, you will fetch data into Pandas DataFrames, perform all the necessary transformations in-memory on the client, and then push the newly transformed DataFrame to the RDBMS data warehouse using a Pandas function that will create the table and fill it with data with a single operation.\n",
    "\n",
    "### Prerequisites:\n",
    "This notebook uses the PyMongo database connectivity library to connect to MySQL databases; therefore, you must have first installed that libary into your python environment by executing the following command in a Terminal window.\n",
    "\n",
    "- `python -m pip install pymongo[srv]`\n",
    "\n",
    "#### Import the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8b95ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy\n",
    "import datetime\n",
    "import certifi\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d7f6f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SQL Alchemy Version: 1.4.39\n",
      "Running PyMongo Version: 4.6.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running SQL Alchemy Version: {sqlalchemy.__version__}\")\n",
    "print(f\"Running PyMongo Version: {pymongo.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c629e4",
   "metadata": {},
   "source": [
    "#### Declare & Assign Connection Variables for the MongoDB Server, the MySQL Server & Databases with which You'll be Working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28890801",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_args = {\n",
    "    \"uid\" : \"root\",\n",
    "    \"pwd\" : \"Passw0rd123\",\n",
    "    \"hostname\" : \"localhost\",\n",
    "    \"dbname\" : \"northwind_dw2\"\n",
    "}\n",
    "\n",
    "# The 'cluster_location' must either be \"atlas\" or \"local\".\n",
    "mongodb_args = {\n",
    "    \"user_name\" : \"root\",\n",
    "    \"password\" : \"Passw0rd123\",\n",
    "    \"cluster_name\" : \"sandbox\",\n",
    "    \"cluster_subnet\" : \"zibbf\",\n",
    "    \"cluster_location\" : \"local\", # \"local\"\n",
    "    \"db_name\" : \"northwind_purchasing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21928a06",
   "metadata": {},
   "source": [
    "#### Define Functions for Getting Data From and Setting Data Into Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eabb5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_dataframe(sql_query, **args):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{args['uid']}:{args['pwd']}@{args['hostname']}/{args['dbname']}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    dframe = pd.read_sql(sql_query, connection);\n",
    "    connection.close()\n",
    "    \n",
    "    return dframe\n",
    "    \n",
    "\n",
    "def set_dataframe(df, table_name, pk_column, db_operation, **args):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{args['uid']}:{args['pwd']}@{args['hostname']}/{args['dbname']}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        connection.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "\n",
    "def get_mongo_client(**args):\n",
    "    '''Validate proper input'''\n",
    "    if args[\"cluster_location\"] not in ['atlas', 'local']:\n",
    "        raise Exception(\"You must specify either 'atlas' or 'local' for the cluster_location parameter.\")\n",
    "    \n",
    "    else:\n",
    "        if args[\"cluster_location\"] == \"atlas\":\n",
    "            connect_str = f\"mongodb+srv://{args['user_name']}:{args['password']}@\"\n",
    "            connect_str += f\"{args['cluster_name']}.{args['cluster_subnet']}.mongodb.net\"\n",
    "            client = pymongo.MongoClient(connect_str, tlsCAFile=certifi.where())\n",
    "            \n",
    "        elif args[\"cluster_location\"] == \"local\":\n",
    "            client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "        \n",
    "    return client\n",
    "\n",
    "\n",
    "def get_mongo_dataframe(mongo_client, db_name, collection, query):\n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = mongo_client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    mongo_client.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_mongo_collections(mongo_client, db_name, data_directory, json_files):\n",
    "    db = mongo_client[db_name]\n",
    "    \n",
    "    for file in json_files:\n",
    "        db.drop_collection(file)\n",
    "        json_file = os.path.join(data_directory, json_files[file])\n",
    "        with open(json_file, 'r') as openfile:\n",
    "            json_object = json.load(openfile)\n",
    "            file = db[file]\n",
    "            result = file.insert_many(json_object)\n",
    "        \n",
    "    mongo_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a3a43",
   "metadata": {},
   "source": [
    "#### Populate MongoDB with Source Data\n",
    "You only need to run this cell once; however, the operation is *idempotent*.  In other words, it can be run multiple times without changing the end result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9772c78a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationFailure",
     "evalue": "bad auth : Authentication failed., full error: {'ok': 0, 'errmsg': 'bad auth : Authentication failed.', 'code': 8000, 'codeName': 'AtlasError'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationFailure\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m json_files \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuppliers\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorthwind_suppliers.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoices\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorthwind_invoices.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpurchase_orders\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorthwind_purchase_orders.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minventory_transactions\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorthwind_inventory_transactions.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m              }\n\u001b[1;32m---> 13\u001b[0m set_mongo_collections(client, mongodb_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdb_name\u001b[39m\u001b[38;5;124m\"\u001b[39m], data_dir, json_files)\n",
      "Cell \u001b[1;32mIn[17], line 62\u001b[0m, in \u001b[0;36mset_mongo_collections\u001b[1;34m(mongo_client, db_name, data_directory, json_files)\u001b[0m\n\u001b[0;32m     59\u001b[0m db \u001b[38;5;241m=\u001b[39m mongo_client[db_name]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m json_files:\n\u001b[1;32m---> 62\u001b[0m     db\u001b[38;5;241m.\u001b[39mdrop_collection(file)\n\u001b[0;32m     63\u001b[0m     json_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_directory, json_files[file])\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m openfile:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\_csot.py:107\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\database.py:1243\u001b[0m, in \u001b[0;36mDatabase.drop_collection\u001b[1;34m(self, name_or_collection, session, comment, encrypted_fields)\u001b[0m\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_helper(\n\u001b[0;32m   1237\u001b[0m         _esc_coll_name(encrypted_fields, name), session\u001b[38;5;241m=\u001b[39msession, comment\u001b[38;5;241m=\u001b[39mcomment\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[0;32m   1239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_helper(\n\u001b[0;32m   1240\u001b[0m         _ecoc_coll_name(encrypted_fields, name), session\u001b[38;5;241m=\u001b[39msession, comment\u001b[38;5;241m=\u001b[39mcomment\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_helper(name, session, comment)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\database.py:1156\u001b[0m, in \u001b[0;36mDatabase._drop_helper\u001b[1;34m(self, name, session, comment)\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m comment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1154\u001b[0m     command[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m comment\n\u001b[1;32m-> 1156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__client\u001b[38;5;241m.\u001b[39m_conn_for_writes(session) \u001b[38;5;28;01mas\u001b[39;00m connection:\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command(\n\u001b[0;32m   1158\u001b[0m         connection,\n\u001b[0;32m   1159\u001b[0m         command,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         session\u001b[38;5;241m=\u001b[39msession,\n\u001b[0;32m   1164\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\mongo_client.py:1252\u001b[0m, in \u001b[0;36mMongoClient._checkout\u001b[1;34m(self, server, session)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_pinned_connection\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1252\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m server\u001b[38;5;241m.\u001b[39mcheckout(handler\u001b[38;5;241m=\u001b[39merr_handler) \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;66;03m# Pin this session to the selected server or connection.\u001b[39;00m\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1255\u001b[0m         in_txn\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m session\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m         )\n\u001b[0;32m   1262\u001b[0m     ):\n\u001b[0;32m   1263\u001b[0m         session\u001b[38;5;241m.\u001b[39m_pin(server, conn)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\pool.py:1637\u001b[0m, in \u001b[0;36mPool.checkout\u001b[1;34m(self, handler)\u001b[0m\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m listeners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1635\u001b[0m     listeners\u001b[38;5;241m.\u001b[39mpublish_connection_check_out_started(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress)\n\u001b[1;32m-> 1637\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_conn(handler\u001b[38;5;241m=\u001b[39mhandler)\n\u001b[0;32m   1639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menabled_for_cmap:\n\u001b[0;32m   1640\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m listeners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\pool.py:1756\u001b[0m, in \u001b[0;36mPool._get_conn\u001b[1;34m(self, handler)\u001b[0m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# We need to create a new connection\u001b[39;00m\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1756\u001b[0m         conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect(handler\u001b[38;5;241m=\u001b[39mhandler)\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1758\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_connecting_cond:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\pool.py:1607\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self, handler)\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m handler:\n\u001b[0;32m   1605\u001b[0m         handler\u001b[38;5;241m.\u001b[39mcontribute_socket(conn, completed_handshake\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1607\u001b[0m     conn\u001b[38;5;241m.\u001b[39mauthenticate()\n\u001b[0;32m   1608\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m   1609\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose_conn(ConnectionClosedReason\u001b[38;5;241m.\u001b[39mERROR)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\pool.py:1078\u001b[0m, in \u001b[0;36mConnection.authenticate\u001b[1;34m(self, reauthenticate)\u001b[0m\n\u001b[0;32m   1076\u001b[0m creds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopts\u001b[38;5;241m.\u001b[39m_credentials\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m creds:\n\u001b[1;32m-> 1078\u001b[0m     auth\u001b[38;5;241m.\u001b[39mauthenticate(creds, \u001b[38;5;28mself\u001b[39m, reauthenticate\u001b[38;5;241m=\u001b[39mreauthenticate)\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menabled_for_cmap:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\auth.py:625\u001b[0m, in \u001b[0;36mauthenticate\u001b[1;34m(credentials, conn, reauthenticate)\u001b[0m\n\u001b[0;32m    623\u001b[0m     _authenticate_oidc(credentials, conn, reauthenticate)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 625\u001b[0m     auth_func(credentials, conn)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\auth.py:530\u001b[0m, in \u001b[0;36m_authenticate_default\u001b[1;34m(credentials, conn)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _authenticate_scram(credentials, conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCRAM-SHA-256\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _authenticate_scram(credentials, conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCRAM-SHA-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _authenticate_scram(credentials, conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCRAM-SHA-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\auth.py:257\u001b[0m, in \u001b[0;36m_authenticate_scram\u001b[1;34m(credentials, conn, mechanism)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     nonce, first_bare, cmd \u001b[38;5;241m=\u001b[39m _authenticate_scram_start(credentials, mechanism)\n\u001b[1;32m--> 257\u001b[0m     res \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcommand(source, cmd)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    260\u001b[0m server_first \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\helpers.py:322\u001b[0m, in \u001b[0;36m_handle_reauth.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_reauth:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\pool.py:968\u001b[0m, in \u001b[0;36mConnection.command\u001b[1;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_not_writable(unacknowledged)\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m command(\n\u001b[0;32m    969\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    970\u001b[0m         dbname,\n\u001b[0;32m    971\u001b[0m         spec,\n\u001b[0;32m    972\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mongos,\n\u001b[0;32m    973\u001b[0m         read_preference,\n\u001b[0;32m    974\u001b[0m         codec_options,\n\u001b[0;32m    975\u001b[0m         session,\n\u001b[0;32m    976\u001b[0m         client,\n\u001b[0;32m    977\u001b[0m         check,\n\u001b[0;32m    978\u001b[0m         allowable_errors,\n\u001b[0;32m    979\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress,\n\u001b[0;32m    980\u001b[0m         listeners,\n\u001b[0;32m    981\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bson_size,\n\u001b[0;32m    982\u001b[0m         read_concern,\n\u001b[0;32m    983\u001b[0m         parse_write_concern_error\u001b[38;5;241m=\u001b[39mparse_write_concern_error,\n\u001b[0;32m    984\u001b[0m         collation\u001b[38;5;241m=\u001b[39mcollation,\n\u001b[0;32m    985\u001b[0m         compression_ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression_context,\n\u001b[0;32m    986\u001b[0m         use_op_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop_msg_enabled,\n\u001b[0;32m    987\u001b[0m         unacknowledged\u001b[38;5;241m=\u001b[39munacknowledged,\n\u001b[0;32m    988\u001b[0m         user_fields\u001b[38;5;241m=\u001b[39muser_fields,\n\u001b[0;32m    989\u001b[0m         exhaust_allowed\u001b[38;5;241m=\u001b[39mexhaust_allowed,\n\u001b[0;32m    990\u001b[0m         write_concern\u001b[38;5;241m=\u001b[39mwrite_concern,\n\u001b[0;32m    991\u001b[0m     )\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (OperationFailure, NotPrimaryError):\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\network.py:192\u001b[0m, in \u001b[0;36mcommand\u001b[1;34m(conn, dbname, spec, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed, write_concern)\u001b[0m\n\u001b[0;32m    190\u001b[0m             client\u001b[38;5;241m.\u001b[39m_process_response(response_doc, session)\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m check:\n\u001b[1;32m--> 192\u001b[0m             helpers\u001b[38;5;241m.\u001b[39m_check_command_response(\n\u001b[0;32m    193\u001b[0m                 response_doc,\n\u001b[0;32m    194\u001b[0m                 conn\u001b[38;5;241m.\u001b[39mmax_wire_version,\n\u001b[0;32m    195\u001b[0m                 allowable_errors,\n\u001b[0;32m    196\u001b[0m                 parse_write_concern_error\u001b[38;5;241m=\u001b[39mparse_write_concern_error,\n\u001b[0;32m    197\u001b[0m             )\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m publish:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\helpers.py:230\u001b[0m, in \u001b[0;36m_check_command_response\u001b[1;34m(response, max_wire_version, allowable_errors, parse_write_concern_error)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m43\u001b[39m:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CursorNotFound(errmsg, code, response, max_wire_version)\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OperationFailure(errmsg, code, response, max_wire_version)\n",
      "\u001b[1;31mOperationFailure\u001b[0m: bad auth : Authentication failed., full error: {'ok': 0, 'errmsg': 'bad auth : Authentication failed.', 'code': 8000, 'codeName': 'AtlasError'}"
     ]
    }
   ],
   "source": [
    "client = get_mongo_client(**mongodb_args)\n",
    "\n",
    "# Gets the path of the Current Working Directory for this Notebook,\n",
    "# and then Appends the 'data' directory.\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "json_files = {\"suppliers\" : 'northwind_suppliers.json',\n",
    "              \"invoices\" : 'northwind_invoices.json',\n",
    "              \"purchase_orders\" : 'northwind_purchase_orders.json',\n",
    "              \"inventory_transactions\" : 'northwind_inventory_transactions.json'\n",
    "             }\n",
    "\n",
    "set_mongo_collections(client, mongodb_args[\"db_name\"], data_dir, json_files)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41747a78",
   "metadata": {},
   "source": [
    "### 1.0. Create and Populate the New Dimension Tables\n",
    "#### 1.1. Extract Data from the Source MongoDB Collections Into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d79acc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidURI",
     "evalue": "The empty string is not valid username.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidURI\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m client \u001b[38;5;241m=\u001b[39m get_mongo_client(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmongodb_args)\n\u001b[0;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;66;03m# Select all elements (columns), and all documents (rows).\u001b[39;00m\n\u001b[0;32m      4\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoices\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 40\u001b[0m, in \u001b[0;36mget_mongo_client\u001b[1;34m(**args)\u001b[0m\n\u001b[0;32m     38\u001b[0m     connect_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongodb+srv://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m     connect_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_subnet\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mongodb.net\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 40\u001b[0m     client \u001b[38;5;241m=\u001b[39m pymongo\u001b[38;5;241m.\u001b[39mMongoClient(connect_str, tlsCAFile\u001b[38;5;241m=\u001b[39mcertifi\u001b[38;5;241m.\u001b[39mwhere())\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_location\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     43\u001b[0m     client \u001b[38;5;241m=\u001b[39m pymongo\u001b[38;5;241m.\u001b[39mMongoClient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongodb://localhost:27017/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\mongo_client.py:771\u001b[0m, in \u001b[0;36mMongoClient.__init__\u001b[1;34m(self, host, port, document_class, tz_aware, connect, type_registry, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mvalidate_timeout_or_none_or_zero(\n\u001b[0;32m    769\u001b[0m         keyword_opts\u001b[38;5;241m.\u001b[39mcased_key(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnecttimeoutms\u001b[39m\u001b[38;5;124m\"\u001b[39m), timeout\n\u001b[0;32m    770\u001b[0m     )\n\u001b[1;32m--> 771\u001b[0m res \u001b[38;5;241m=\u001b[39m uri_parser\u001b[38;5;241m.\u001b[39mparse_uri(\n\u001b[0;32m    772\u001b[0m     entity,\n\u001b[0;32m    773\u001b[0m     port,\n\u001b[0;32m    774\u001b[0m     validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    775\u001b[0m     warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    776\u001b[0m     normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    777\u001b[0m     connect_timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    778\u001b[0m     srv_service_name\u001b[38;5;241m=\u001b[39msrv_service_name,\n\u001b[0;32m    779\u001b[0m     srv_max_hosts\u001b[38;5;241m=\u001b[39msrv_max_hosts,\n\u001b[0;32m    780\u001b[0m )\n\u001b[0;32m    781\u001b[0m seeds\u001b[38;5;241m.\u001b[39mupdate(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodelist\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    782\u001b[0m username \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m username\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\uri_parser.py:534\u001b[0m, in \u001b[0;36mparse_uri\u001b[1;34m(uri, default_port, validate, warn, normalize, connect_timeout, srv_service_name, srv_max_hosts)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m host_part:\n\u001b[0;32m    533\u001b[0m     userinfo, _, hosts \u001b[38;5;241m=\u001b[39m host_part\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 534\u001b[0m     user, passwd \u001b[38;5;241m=\u001b[39m parse_userinfo(userinfo)\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    536\u001b[0m     hosts \u001b[38;5;241m=\u001b[39m host_part\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\uri_parser.py:93\u001b[0m, in \u001b[0;36mparse_userinfo\u001b[1;34m(userinfo)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# No password is expected with GSSAPI authentication.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURI(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe empty string is not valid username.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unquote_plus(user), unquote_plus(passwd)\n",
      "\u001b[1;31mInvalidURI\u001b[0m: The empty string is not valid username."
     ]
    }
   ],
   "source": [
    "client = get_mongo_client(**mongodb_args)\n",
    "\n",
    "query = {} # Select all elements (columns), and all documents (rows).\n",
    "collection = \"invoices\"\n",
    "\n",
    "df_invoices = get_mongo_dataframe(client, mongodb_args[\"db_name\"], collection, query)\n",
    "df_invoices.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4957b66",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidURI",
     "evalue": "The empty string is not valid username.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidURI\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Extract data from the \"Suppliers\" collection\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m get_mongo_client(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmongodb_args)\n\u001b[0;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      5\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuppliers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 40\u001b[0m, in \u001b[0;36mget_mongo_client\u001b[1;34m(**args)\u001b[0m\n\u001b[0;32m     38\u001b[0m     connect_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongodb+srv://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m     connect_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_subnet\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mongodb.net\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 40\u001b[0m     client \u001b[38;5;241m=\u001b[39m pymongo\u001b[38;5;241m.\u001b[39mMongoClient(connect_str, tlsCAFile\u001b[38;5;241m=\u001b[39mcertifi\u001b[38;5;241m.\u001b[39mwhere())\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_location\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     43\u001b[0m     client \u001b[38;5;241m=\u001b[39m pymongo\u001b[38;5;241m.\u001b[39mMongoClient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongodb://localhost:27017/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\mongo_client.py:771\u001b[0m, in \u001b[0;36mMongoClient.__init__\u001b[1;34m(self, host, port, document_class, tz_aware, connect, type_registry, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mvalidate_timeout_or_none_or_zero(\n\u001b[0;32m    769\u001b[0m         keyword_opts\u001b[38;5;241m.\u001b[39mcased_key(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnecttimeoutms\u001b[39m\u001b[38;5;124m\"\u001b[39m), timeout\n\u001b[0;32m    770\u001b[0m     )\n\u001b[1;32m--> 771\u001b[0m res \u001b[38;5;241m=\u001b[39m uri_parser\u001b[38;5;241m.\u001b[39mparse_uri(\n\u001b[0;32m    772\u001b[0m     entity,\n\u001b[0;32m    773\u001b[0m     port,\n\u001b[0;32m    774\u001b[0m     validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    775\u001b[0m     warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    776\u001b[0m     normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    777\u001b[0m     connect_timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    778\u001b[0m     srv_service_name\u001b[38;5;241m=\u001b[39msrv_service_name,\n\u001b[0;32m    779\u001b[0m     srv_max_hosts\u001b[38;5;241m=\u001b[39msrv_max_hosts,\n\u001b[0;32m    780\u001b[0m )\n\u001b[0;32m    781\u001b[0m seeds\u001b[38;5;241m.\u001b[39mupdate(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodelist\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    782\u001b[0m username \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m username\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\uri_parser.py:534\u001b[0m, in \u001b[0;36mparse_uri\u001b[1;34m(uri, default_port, validate, warn, normalize, connect_timeout, srv_service_name, srv_max_hosts)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m host_part:\n\u001b[0;32m    533\u001b[0m     userinfo, _, hosts \u001b[38;5;241m=\u001b[39m host_part\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 534\u001b[0m     user, passwd \u001b[38;5;241m=\u001b[39m parse_userinfo(userinfo)\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    536\u001b[0m     hosts \u001b[38;5;241m=\u001b[39m host_part\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymongo\\uri_parser.py:93\u001b[0m, in \u001b[0;36mparse_userinfo\u001b[1;34m(userinfo)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# No password is expected with GSSAPI authentication.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURI(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe empty string is not valid username.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unquote_plus(user), unquote_plus(passwd)\n",
      "\u001b[1;31mInvalidURI\u001b[0m: The empty string is not valid username."
     ]
    }
   ],
   "source": [
    "# TODO: Extract data from the \"Suppliers\" collection\n",
    "client = get_mongo_client(**mongodb_args)\n",
    "\n",
    "query = {}\n",
    "collection = \"suppliers\"\n",
    "\n",
    "df_suppliers = get_mongo_dataframe(client, mongodb_args[\"db_name\"], collection, query)\n",
    "df_suppliers.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c2715",
   "metadata": {},
   "source": [
    "#### 1.2. Lookup the Invoice Date Keys from the Date Dimension Table.\n",
    "Here we see an example of where a dimension cross-references another dimension; the Date dimension.  The Date dimension is a classic example of a **Role-Playing dimension**. Dates in-and-of themselves are universal; however, when applied to specific events they take on the identity of those events. Here, the *dim_date* table takes on the identity of *dim_invoice_date* to supply invoice date keys to the *dim_invoices* table.\n",
    "\n",
    "##### 1.2.1. Get the Data from the Date Dimension Table.\n",
    "First, fetch the Surrogate Primary Key (date_key) and the Business Key (full_date) from the Date Dimension table using the **get_sql_dataframe()** function. Be certain to cast the **full_date** column to the **datetime64[ns]** data type using the **.astype()** function that is native to Pandas DataFrame columns. Also, extract the **date** portion using the **.dt.date** attribute of the **datetime64[ns]** datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2f7c6c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(pymysql.err.ProgrammingError) (1146, \"Table 'northwind_dw2.dim_date' doesn't exist\")\n[SQL: SELECT date_key, full_date FROM northwind_dw2.dim_date;]\n(Background on this error at: https://sqlalche.me/e/14/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[0;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    151\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmogrify(query, args)\n\u001b[1;32m--> 153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(query)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_result()\n\u001b[1;32m--> 322\u001b[0m conn\u001b[38;5;241m.\u001b[39mquery(q)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:558\u001b[0m, in \u001b[0;36mConnection.query\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(COMMAND\u001b[38;5;241m.\u001b[39mCOM_QUERY, sql)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_query_result(unbuffered\u001b[38;5;241m=\u001b[39munbuffered)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:822\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    821\u001b[0m     result \u001b[38;5;241m=\u001b[39m MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 822\u001b[0m     result\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:1200\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1200\u001b[0m     first_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_read_packet()\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_packet\u001b[38;5;241m.\u001b[39mis_ok_packet():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:772\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 772\u001b[0m     packet\u001b[38;5;241m.\u001b[39mraise_for_error()\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\protocol.py:221\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[1;32m--> 221\u001b[0m err\u001b[38;5;241m.\u001b[39mraise_mysql_exception(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\err.py:143\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    142\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (1146, \"Table 'northwind_dw2.dim_date' doesn't exist\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sql_dim_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT date_key, full_date FROM northwind_dw2.dim_date;\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m df_dim_date \u001b[38;5;241m=\u001b[39m get_sql_dataframe(sql_dim_date, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmysql_args)\n\u001b[0;32m      3\u001b[0m df_dim_date\u001b[38;5;241m.\u001b[39mfull_date \u001b[38;5;241m=\u001b[39m df_dim_date\u001b[38;5;241m.\u001b[39mfull_date\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[ns]\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[0;32m      4\u001b[0m df_dim_date\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m, in \u001b[0;36mget_sql_dataframe\u001b[1;34m(sql_query, **args)\u001b[0m\n\u001b[0;32m      5\u001b[0m connection \u001b[38;5;241m=\u001b[39m sqlEngine\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m dframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(sql_query, connection);\n\u001b[0;32m      9\u001b[0m connection\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dframe\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:590\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    582\u001b[0m         sql,\n\u001b[0;32m    583\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    587\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    588\u001b[0m     )\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[0;32m    591\u001b[0m         sql,\n\u001b[0;32m    592\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m    593\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    594\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[0;32m    595\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m    596\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    597\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1560\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;124;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 1560\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1561\u001b[0m columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1405\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectable\u001b[38;5;241m.\u001b[39mexecution_options()\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1291\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(statement, util\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[0;32m   1283\u001b[0m     util\u001b[38;5;241m.\u001b[39mwarn_deprecated_20(\n\u001b[0;32m   1284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a string to Connection.execute() is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in version 2.0.  Use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver-level SQL string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1289\u001b[0m     )\n\u001b[1;32m-> 1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_driver_sql(\n\u001b[0;32m   1292\u001b[0m         statement,\n\u001b[0;32m   1293\u001b[0m         multiparams,\n\u001b[0;32m   1294\u001b[0m         params,\n\u001b[0;32m   1295\u001b[0m         _EMPTY_EXECUTION_OPTS,\n\u001b[0;32m   1296\u001b[0m         future\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1297\u001b[0m     )\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1300\u001b[0m     meth \u001b[38;5;241m=\u001b[39m statement\u001b[38;5;241m.\u001b[39m_execute_on_connection\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1595\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[1;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[0;32m   1585\u001b[0m         (\n\u001b[0;32m   1586\u001b[0m             statement,\n\u001b[0;32m   1587\u001b[0m             distilled_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1591\u001b[0m             statement, distilled_parameters, execution_options\n\u001b[0;32m   1592\u001b[0m         )\n\u001b[0;32m   1594\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[1;32m-> 1595\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[0;32m   1596\u001b[0m     dialect,\n\u001b[0;32m   1597\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_statement,\n\u001b[0;32m   1598\u001b[0m     statement,\n\u001b[0;32m   1599\u001b[0m     distilled_parameters,\n\u001b[0;32m   1600\u001b[0m     execution_options,\n\u001b[0;32m   1601\u001b[0m     statement,\n\u001b[0;32m   1602\u001b[0m     distilled_parameters,\n\u001b[0;32m   1603\u001b[0m )\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future:\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1859\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[0;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[0;32m   1864\u001b[0m     )\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2043\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2041\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(newraise, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m   2042\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m-> 2043\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[0;32m   2044\u001b[0m         sqlalchemy_exception, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me\n\u001b[0;32m   2045\u001b[0m     )\n\u001b[0;32m   2046\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2047\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(exc_info[\u001b[38;5;241m1\u001b[39m], with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1817\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[0;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1826\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1830\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1831\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    151\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmogrify(query, args)\n\u001b[1;32m--> 153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(query)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    320\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_result()\n\u001b[1;32m--> 322\u001b[0m conn\u001b[38;5;241m.\u001b[39mquery(q)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_result()\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:558\u001b[0m, in \u001b[0;36mConnection.query\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    556\u001b[0m     sql \u001b[38;5;241m=\u001b[39m sql\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(COMMAND\u001b[38;5;241m.\u001b[39mCOM_QUERY, sql)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_query_result(unbuffered\u001b[38;5;241m=\u001b[39munbuffered)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:822\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    821\u001b[0m     result \u001b[38;5;241m=\u001b[39m MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 822\u001b[0m     result\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mserver_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:1200\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1200\u001b[0m         first_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_read_packet()\n\u001b[0;32m   1202\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m first_packet\u001b[38;5;241m.\u001b[39mis_ok_packet():\n\u001b[0;32m   1203\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_ok_packet(first_packet)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:772\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 772\u001b[0m     packet\u001b[38;5;241m.\u001b[39mraise_for_error()\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\protocol.py:221\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[1;32m--> 221\u001b[0m err\u001b[38;5;241m.\u001b[39mraise_mysql_exception(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\err.py:143\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (pymysql.err.ProgrammingError) (1146, \"Table 'northwind_dw2.dim_date' doesn't exist\")\n[SQL: SELECT date_key, full_date FROM northwind_dw2.dim_date;]\n(Background on this error at: https://sqlalche.me/e/14/f405)"
     ]
    }
   ],
   "source": [
    "sql_dim_date = \"SELECT date_key, full_date FROM northwind_dw2.dim_date;\"\n",
    "df_dim_date = get_sql_dataframe(sql_dim_date, **mysql_args)\n",
    "df_dim_date.full_date = df_dim_date.full_date.astype('datetime64[ns]').dt.date\n",
    "df_dim_date.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47178c4",
   "metadata": {},
   "source": [
    "##### 1.2.2. Lookup the Surrogate Primary Key (date_key) that Corresponds to the invoice_date Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e7a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_invoice_date = df_dim_date.rename(columns={\"date_key\" : \"invoice_date_key\", \"full_date\" : \"invoice_date\"})\n",
    "df_invoices.invoice_date = df_invoices.invoice_date.astype('datetime64[ns]').dt.date\n",
    "df_invoices = pd.merge(df_invoices, df_dim_invoice_date, on='invoice_date', how='left')\n",
    "df_invoices.drop(['invoice_date'], axis=1, inplace=True)\n",
    "df_invoices.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10272202",
   "metadata": {},
   "source": [
    "#### 1.3. Perform Any Necessary Transformations to the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Rename the \"id\" column to reflect the entity as it will serve as the business key for lookup operations\n",
    "df_invoices.rename(columns={\"id\":\"invoice_id\"}, inplace=True)\n",
    "\n",
    "# 2. Since there are no values in the 'due_date' column go ahead and drop it.\n",
    "df_invoices.drop(['due_date'], axis=1, inplace=True)\n",
    "\n",
    "# 3. Insert a new column, with an ever-incrementing numeric value, to serve as the primary key.\n",
    "df_invoices.insert(0, \"invoice_key\", range(1, df_invoices.shape[0]+1))\n",
    "df_invoices.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ba2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. TODO: Rename the \"id\" column to reflect the entity as it will serve as the business key for lookup operations\n",
    "df_suppliers.rename(columns={\"id\":\"supplier_id\"}, inplace=True)\n",
    "# 2. TODO: Insert a new column, with an ever-incrementing numeric value, to serve as the primary key.\n",
    "df_suppliers.insert(0, \"supplier_key\", range(1, df_suppliers.shape[0] + 1))\n",
    "df_suppliers.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd16f44",
   "metadata": {},
   "source": [
    "#### 1.3. Load the Transformed DataFrames into the New Data Warehouse by Creating New Tables\n",
    "\n",
    "Here we will call our **set_dataframe( )** function to create each dimension table. This function expects a number of parameters including the usual connection information (e.g., user_id, password, MySQL server name and database), the *table_name* we need to assign to the table, the *pandas DataFrame* we crafted to define & populate the table, the *name* of the column we wish to designate as the *primary_key* column, and finally, the database operation (insert or update). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28460874",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df_invoices\n",
    "table_name = 'dim_invoices'\n",
    "primary_key = 'invoice_key'\n",
    "db_operation = \"insert\"\n",
    "\n",
    "set_dataframe(dataframe, table_name, primary_key, db_operation, **mysql_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Upload the \"Suppliers\" dataframe to create the new \"dim_suppliers\" dimension table\n",
    "dataframe = df_suppliers\n",
    "table_name = \"dim_invoices\"\n",
    "primary_key = 'invoice_key'\n",
    "db_opertaion = 'insert'\n",
    "\n",
    "set_dataframe(dataframe, table_name, primary_key, db_operation, **mysql_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2411d8e",
   "metadata": {},
   "source": [
    "#### 1.4. Validate that the New Dimension Tables were Created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_invoices = \"SELECT * FROM northwind_dw2.dim_invoices;\"\n",
    "df_dim_invoices = get_sql_dataframe(sql_invoices, **mysql_args)\n",
    "df_dim_invoices.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ed928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate the new \"dim_suppliers\" table in the northwind_dw2 data warehouse.\n",
    "sql_suppliers = \"SELECT * FROM northwind_dw2.dim_suppliers;\"\n",
    "df_dim_suppliers = get_sql_dataframe(sql_suppliers, **mysql_args)\n",
    "df_dim_suppliers.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b015eb8e",
   "metadata": {},
   "source": [
    "### 2.0. Create and Populate the New Fact Tables\n",
    "#### 2.1. Extract Data from the Source MongoDB Collections Into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_mongo_client(**mongodb_args)\n",
    "\n",
    "query = {} # Select all elements (columns), and all documents (rows).\n",
    "collection = \"purchase_orders\"\n",
    "\n",
    "df_fact_pos = get_mongo_dataframe(client, mongodb_args[\"db_name\"], collection, query)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5e338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Extract data for your new \"Inventory Transactions\" Fact Table\n",
    "query = {}\n",
    "\n",
    "collection = \"inventory_transactions\"\n",
    "\n",
    "df_fact_pos = get_mongo_dataframe(conn_str['atlas'], src_dbname, collection, query)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a44de",
   "metadata": {},
   "source": [
    "#### 2.2. Lookup the DateKeys from the Date Dimension Table.\n",
    "**2.2.1.** For each date typed column in the **purchase orders** fact table, lookup the corresponding Surrogate Primary Key column. Be certain to cast the date typed column to the **datetime64[ns]** data type using the **.astype()** function that is native to Pandas DataFrame columns. Also, extract the **date** portion using the **.dt.date** attribute of the **datetime64[ns]** datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a5f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup the Surrogate Primary Key (date_key) that Corresponds to the \"submitted_date\" Column.\n",
    "df_dim_submitted_date = df_dim_date.rename(columns={\"date_key\" : \"submitted_date_key\", \"full_date\" : \"submitted_date\"})\n",
    "df_fact_pos.submitted_date = df_fact_pos.submitted_date.astype('datetime64[ns]').dt.date\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_dim_submitted_date, on='submitted_date', how='left')\n",
    "df_fact_pos.drop(['submitted_date'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf261cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lookup the Primary Key (date_key) that Corresponds to the \"creation_date\" Column.\n",
    "df_dim_creation_date = df_dim_date.rename(columns={\"date_key\" : \"creation_date_key\", \"full_date\" : \"creation_date\"})\n",
    "df_fact_pos.creation_date = df_fact_pos.creation_date.astype('datetime64[ns]').dt.date\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_creation_date_date, on='creation_date', how='left')\n",
    "df_fact_pos.drop(['creation_date'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b34ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lookup the Primary Key (date_key) that Corresponds to the \"po_detail_date_received\" Column.\n",
    "df_dim_po_detail_date_received = df_dim_date.rename(columns={\"date_key\" : \"po_detail_date_received_key\", \"full_date\" : \"po_detail_date_received\"})\n",
    "df_fact_pos.po_detail_date_received = df_fact_pos.po_detail_date_received.astype('datetime64[ns]').dt.date\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_po_detail_date_received, on='po_detail_date_received', how='left')\n",
    "df_fact_pos.drop(['po_detail_date_received'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f436d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lookup the Primary Key (date_key) that Corresponds to the \"approved_date\" Column.\n",
    "df_dim_approved_date = df_dim_date.rename(columns={\"date_key\" : \"approved_date_key\", \"full_date\" : \"approved_date\"})\n",
    "df_fact_pos.approved_date = df_fact_pos.approved_date.astype('datetime64[ns]').dt.date\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_dim_approved_date, on='approved_date', how='left')\n",
    "df_fact_pos.drop(['approved_date'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0525b9e",
   "metadata": {},
   "source": [
    "**2.2.2.** Then, for each date typed column in the **inventory transaction** fact table, lookup the corresponding Surrogate Primary Key column. Be certain to cast the date typed column to the **datetime64[ns]** data type using the **.astype()** function, and extract the **date** portion using the **.dt.date** attribute of the **datetime64[ns]** datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ac310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lookup the Primary Key (date_key) that Corresponds to the \"transaction_created_date\" Column.\n",
    "df_dim_transaction_created_date = df_dim_transaction_created_date.rename(columns={\"date_key\" : \"transaction_created_date_key\", \"full_date\" : \"transaction_created_date\"})\n",
    "df_fact_pos.transaction_created_date = df_fact_pos.transaction_created_date.astype('datetime64[ns]').dt.date\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_dim_transaction_created_date, on='transaction_created_date', how='left')\n",
    "df_fact_pos.drop(['transaction_created_date'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)\n",
    "\n",
    "df_fact_inventory.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896afa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lookup the Primary Key (date_key) that Corresponds to the \"transaction_modified_date\" Column.\n",
    "df_dim_transaction_modified_date = df_dim_transaction_modified_date.rename(columns={\"date_key\" : \"transaction_modified_date_key\", \"full_date\" : \"transaction_modified_date\"})\n",
    "df_fact_pos.transaction_modified_date = df_fact_pos.transaction_modified_date.astype('datetime64[ns]').dt.date\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_transaction_modified_date, on='transaction_modified_date', how='left')\n",
    "df_fact_pos.drop(['transaction_modified_date'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)\n",
    "\n",
    "df_fact_inventory.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece03fd",
   "metadata": {},
   "source": [
    "#### 2.3. Lookup the Primary Keys from the Dimension Tables\n",
    "**Foreign key relationships** must be established between each newly-crafted **Fact table** and each related **Dimension table**.\n",
    "\n",
    "##### 2.3.1. First, fetch the Surrogate Primary Key and the Business Key from each Dimension table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dim_invoices = \"SELECT invoice_key, invoice_id FROM northwind_dw2.dim_invoices;\"\n",
    "df_dim_invoices = get_sql_dataframe(sql_dim_invoices, **mysql_args)\n",
    "df_dim_invoices.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract the 'primary key' and the 'business key' from your new \"dim_suppliers\" dimension table\n",
    "sql_dim_suppliers = \"SELECT supplier_key, supplier_id FROM northwind_dw2.dim_supplier;\"\n",
    "df_dim_supplier = get_sql_dataframe(sql_dim_supplier, **mysql_args)\n",
    "df_dim_invoices.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract the 'primary key' and the 'business key' from the \"dim_employees\" dimension table\n",
    "sql_dim_employees = \"SELECT employee_key, employee_id FROM northwind_dw2.dim_employees;\"\n",
    "df_dim_employees = get_sql_dataframe(sql_dim_employees, **mysql_args)\n",
    "df_dim_employees.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract the 'primary key' and the 'business key' from the \"dim_products\" dimension table\n",
    "sql_dim_products = \"SELECT product_key, product_id FROM northwind_dw2.dim_product;\"\n",
    "df_dim_products = get_sql_dataframe(sql_dim_product, **mysql_args)\n",
    "df_dim_products.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16c4d7",
   "metadata": {},
   "source": [
    "##### 2.3.2. Next, use Business Keys to lookup corresponding Surrogate Primary Keys in the Dimension tables\n",
    "**2.3.2.1. Inventory Fact table.**  The inventory fact table contains a reference to the *dim_products* table by way of the *product_id* column that enables us to lookup the corresponding *product_key*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge the \"fact_inventory\" and \"dim_products\" dataframes on the 'product_id' to\n",
    "# get the 'product_key'. Then drop the 'product_id' column and display the results.\n",
    "df_fact_products = pd.merge(fact_inventory, dim_products, on='product_id', how='inner')\n",
    "df_fact_products.drop(['product_id'], axis=1, inplace=True)\n",
    "df_fact_products.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Insert a new 'fact_inventory_transaction_key' column, with an ever-incrementing\n",
    "# numeric value, to serve as the surrogate primary key. Then display the results.\n",
    "df_fact_products.insert(0, \"fact_inventory_transaction_key\", range(1, df_fact_products.shape[0]+1))\n",
    "df_fact_products.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e65e4",
   "metadata": {},
   "source": [
    "**2.3.2.2. Purchase Order Fact table**. Here we see another example of a **role-playing dimension**; the *Employee* dimension. The employee dimension is another classic example of a Role-Playing dimension. In-and-of themselves Employees are generic; however, when applied to specific roles they take on the identity of those positions (roles). Here, the *dim_employee* table takes on the identities of *creator, approver, and submitter* in supplying employee keys to the *dim_fact_pos* table.\n",
    "\n",
    "We also see an example of where one fact table is referenced by another fact table as if it were a dimension table; i.e., a **fact dimension.** In this instance the purchase orders table *fact_pos* contains a reference to the inventory transaction table *fact_inventory* by way of the *inventory_transaction_id* column, enabling us to lookup the corresponding *fact_inventory_key*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc2c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup the Surrogate Primary Key (employee_key) that Corresponds to the \"created_by\" Column.\n",
    "df_dim_creator = df_dim_employees.rename(columns={\"employee_key\":\"created_by_key\", \"employee_id\":\"created_by\"})\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_dim_creator, on='created_by', how='inner')\n",
    "df_fact_pos.drop(['created_by'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f86ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lookup the Surrogate Primary Key (employee_key) that Corresponds to the \"approved_by\" Column.\n",
    "df_dim_approver = df_dim_employees.rename(columns={\"employee_key\":\"approved_by_key\", \"employee_id\":\"approved_by\"})\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_dim_approver, on='approved_by', how='inner')\n",
    "df_fact_pos.drop(['approved_by'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lookup the Surrogate Primary Key (employee_key) that Corresponds to the \"submitted_by\" Column.\n",
    "df_dim_submitter = df_dim_employees.rename(columns={\"employee_key\":\"submitted_by_key\", \"employee_id\":\"submitted_by\"})\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_dim_submitter, on='submitted_by', how='inner')\n",
    "df_fact_pos.drop(['submitted_by'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b16a1d",
   "metadata": {},
   "source": [
    "Since the *df_fact_pos* fact table contains references to suppliers and products, lookup the surrogate primary keys from the *dim_suppliers* and *dim_products* tables that correspond to the *supplier_id* and *product_id* columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lookup the Surrogate Primary Key (supplier_key) that Corresponds to the \"supplier_id\" Column.\n",
    "df_dim_supplier = df_dim_supplier.rename(columns={\"suppplier_key\":\"supplier_id_key\", \"employee_id\":\"suppplier_id\"})\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_dim_supplier, on='supplier_id', how='inner')\n",
    "df_fact_pos.drop(['supplier_id'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lookup the Primary Key (product_key) that Corresponds to the \"po_detail_product_id\" Column.\n",
    "# Remember that you'll first have to rename it to \"product_id\" in the \"df_fact_pos\" dataframe.\n",
    "df_dim_products = df_dim_employees.rename(columns={\"product_key\":\"po_detail_product_id_key\", \"employee_id\":\"po_detail_supplier_id\"})\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_dim_products, on='po_detail_product_id', how='inner')\n",
    "df_fact_pos.drop(['po_detail_product_idy'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ac1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Insert a new \"fact_purchase_order_key\" column, with an ever-incrementing \n",
    "# numeric value, to serve as the surrogate primary key. Then display the results.\n",
    "df_fact_pos.insert(0, \"fact_purchase_order_key\", range(1, df_fact_pos.shape[0]+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0a022",
   "metadata": {},
   "source": [
    "Since the purchase orders table *fact_pos* contains a reference to the inventory transaction table *fact_inventory* by way of the *inventory_transaction_id* column, we can lookup the corresponding *fact_inventory_transaction_key*. In this case, the *fact_inventory* table plays the role of a dimension table. This is called a **fact dimension**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The inventory fact table acts as a Fact Dimension: po_detail_inventory_id\n",
    "df_dim_fact_inventory = df_fact_inventory[['fact_inventory_transaction_key','inventory_transaction_id']]\n",
    "df_fact_pos.rename(columns={\"po_detail_inventory_id\":\"inventory_transaction_id\"}, inplace=True)\n",
    "df_fact_pos = pd.merge(df_fact_pos, df_dim_fact_inventory, on='inventory_transaction_id', how='left')\n",
    "df_fact_pos.drop(['inventory_transaction_id'], axis=1, inplace=True)\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ef721",
   "metadata": {},
   "source": [
    "#### 2.4. Perform Any Necessary Transformations to the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5312f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Foreign Key Columns\n",
    "column_name_map = {\"transaction_created_date_key\" : \"created_date_key\",\n",
    "                   \"transaction_modified_date_key\" : \"modified_date_key\",\n",
    "                  }\n",
    "\n",
    "df_fact_inventory.rename(columns=column_name_map, inplace=True)\n",
    "\n",
    "# Reorder the Columns\n",
    "ordered_columns = ['fact_inventory_transaction_key','inventory_transaction_id'\n",
    "                   ,'inventory_transaction_type','product_key'\n",
    "                   ,'created_date_key','modified_date_key','quantity']\n",
    "\n",
    "df_fact_inventory = df_fact_inventory[ordered_columns]\n",
    "df_fact_inventory.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977189aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the 'po_detail_posted_to_inventory' column values from 1 and 0 to 'True' and 'False'.\n",
    "df_fact_pos['posted_to_inventory'] = df_fact_pos.po_detail_posted_to_inventory.map({1 :'True', 0 :'False'})\n",
    "df_fact_pos.drop('po_detail_posted_to_inventory', axis=1, inplace=True)\n",
    "df_fact_pos.rename(columns={'posted_to_inventory' : 'po_detail_posted_to_inventory'}, inplace=True)\n",
    "\n",
    "# Reorder the Columns\n",
    "reordered_columns = ['fact_purchase_order_key','purchase_order_id','supplier_key','product_key'\n",
    "                     ,'fact_inventory_transaction_key','created_by_key','creation_date_key'\n",
    "                     ,'submitted_by_key','submitted_date_key','approved_by_key','approved_date_key'\n",
    "                     ,'purchase_order_status','po_detail_date_received_key'\n",
    "                     ,'po_detail_posted_to_inventory','po_detail_unit_cost','po_detail_quantity'\n",
    "                     ,'shipping_fee','taxes','payment_date','payment_amount']\n",
    "\n",
    "df_fact_pos = df_fact_pos[reordered_columns]\n",
    "df_fact_pos.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a226d",
   "metadata": {},
   "source": [
    "#### 2.5. Load Newly Transformed MongoDB Data into the Northwind_DW2 Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df_fact_pos\n",
    "table_name = 'fact_purchase_orders'\n",
    "primary_key = 'fact_purchase_order_key'\n",
    "db_operation = \"insert\"\n",
    "\n",
    "set_dataframe(dataframe, table_name, primary_key, db_operation, **mysql_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf15520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Upload the \"Inventory Transaction\" dataframe to create the new \"fact_inventory_transactions\" fact table. \n",
    "dataframe = df_fact_inventory\n",
    "table_name = 'fact_inventory_transactions'\n",
    "primary_key = 'fact_inventory_transaction_key'\n",
    "db_operation = \"insert\"\n",
    "\n",
    "set_dataframe(dataframe, table_name, primary_key, db_operation, **mysql_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58a3d2",
   "metadata": {},
   "source": [
    "#### 2.6. Validate that the New Fact Tables were Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate the correctness of the new \"Purchase Orders\" fact table.\n",
    "sql_purchase_orders = \"SELECT * FROM northwind_dw2.fact_purchase_orders;\"\n",
    "df_fact_purchase_orders = get_sql_dataframe(sql_purchase_orders, **mysql_args)\n",
    "df_fact_purchase_orders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate the correctness of the new \"Inventory Transactions\" fact table.\n",
    "sql_inventory_transactions = \"SELECT * FROM northwind_dw2.fact_inventory_transactions;\"\n",
    "df_fact_inventory_transactions = get_sql_datafrane(sql_inventory_transactions, **mysql_args)\n",
    "df_fact_inventory_transactions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d09f3",
   "metadata": {},
   "source": [
    "### 3.0. Demonstrate that the New Data Warehouse Exists and Contains the Correct Data\n",
    "To demonstrate the viability of your solution, author a SQL SELECT statement that returns:\n",
    "- Each Companys Name\n",
    "- The total amount of the purchase order detail quantity associated with each company\n",
    "- The total amount of the purchase order detail unit cost associated with each company\n",
    "\n",
    "**NOTE:** *Remember that a string typed variable whose value is contained by triple-quotes (\"\"\" ... \"\"\") can preserve multi-line formatting, and that a string variable has an intrinsic **.format()** function that accepts ordered parameters that will replace tokens (e.g., {0}) in the formatted string.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd46161",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_purchase_orders = \"\"\"\n",
    "    SELECT s.company AS 'Company'\n",
    "        , FORMAT(SUM(po.po_detail_quantity),0) AS 'Total Quantity'\n",
    "        , FORMAT(SUM(po.po_detail_unit_cost),2) AS 'Total Unit Cost'\n",
    "    FROM northwind_dw2.fact_purchase_orders AS po\n",
    "    INNER JOIN northwind_dw2.dim_suppliers AS s\n",
    "    ON po.supplier_key = s.supplier_key\n",
    "    GROUP BY s.company\n",
    "    ORDER BY 'Total Unit Cost' DESC;\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50dfbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_purchase_orders = get_sql_dataframe(sql_purchase_orders, **mysql_args)\n",
    "df_fact_purchase_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895795cb",
   "metadata": {},
   "source": [
    "### 3.1 Extra Credit: Author a Query that Returns the Inventory Transaction Data\n",
    "- Each Product Category\n",
    "- Each TransactionType\n",
    "- The total number of transactions associated with each Product Category and Transaction Type\n",
    "- The total amount (quantity) associated with each Product Category and Transaction Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b9b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_inventory_transactions = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b070189",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_inventory_transactions = get_sql_dataframe(sql_inventory_transactions, **mysql_args)\n",
    "df_fact_inventory_transactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
